{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_part3.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Somraj Gautam"
      ],
      "metadata": {
        "id": "NUKDsWOuAsz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Results on one database which was not used in the paper"
      ],
      "metadata": {
        "id": "MT_exVeGtFDl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "New Dataset- Weather Dataset: - https://www.kaggle.com/datasets/vijaygiitk/multiclass-weather-dataset"
      ],
      "metadata": {
        "id": "uozppTG31HI1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle"
      ],
      "metadata": {
        "id": "cmo9k-swP0L6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "8OJSZN3vP1Ac",
        "outputId": "cf6f8526-6a1c-480b-fc04-dc3756519708"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0ba89215-bb7d-4d8c-bbf3-3361f92cdb86\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0ba89215-bb7d-4d8c-bbf3-3361f92cdb86\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"somraj09\",\"key\":\"997d1ba4e8a48a85fa75bb9e7f1ec34e\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxvbgnNkQFp_",
        "outputId": "75a7031c-a4b5-47d3-f887-746a62ec5d7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d vijaygiitk/multiclass-weather-dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "en3btiYZP7nu",
        "outputId": "5626a5d7-95cf-422f-82dd-fc4b371c9d77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading multiclass-weather-dataset.zip to /content\n",
            " 98% 132M/134M [00:01<00:00, 79.5MB/s]\n",
            "100% 134M/134M [00:01<00:00, 78.4MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/multiclass-weather-dataset.zip"
      ],
      "metadata": {
        "id": "bCWFbQZLQIyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torchvision\n",
        "import argparse\n",
        "from torch.utils import data\n",
        "import torch.nn as nn\n",
        "import math\n",
        "import torch\n",
        "from torch.nn.functional import normalize\n",
        "from torchvision.models.resnet import Bottleneck, BasicBlock, conv1x1\n",
        "import cv2\n",
        "from sklearn import metrics\n",
        "import os\n",
        "import copy"
      ],
      "metadata": {
        "id": "Yrr9TSek9bG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function for saving the model at different epochs"
      ],
      "metadata": {
        "id": "ubwifPJYtOm9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_model(args, model, optimizer, current_epoch):\n",
        "    out = os.path.join('/content/Model', \"checkpoint_{}.tar\".format(current_epoch))\n",
        "    state = {'net': model.state_dict(), 'optimizer': optimizer.state_dict(), 'epoch': current_epoch}\n",
        "    torch.save(state, out)"
      ],
      "metadata": {
        "id": "ZnOUKEYJMmwu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### For calculating loss"
      ],
      "metadata": {
        "id": "BNWGHbQFta16"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class InstanceLoss(nn.Module):\n",
        "    def __init__(self, batch_size, temperature, device):\n",
        "        super(InstanceLoss, self).__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.temperature = temperature\n",
        "        self.device = device\n",
        "\n",
        "        self.mask = self.mask_correlated_samples(batch_size)\n",
        "        self.criterion = nn.CrossEntropyLoss(reduction=\"sum\")\n",
        "\n",
        "    def mask_correlated_samples(self, batch_size):\n",
        "        N = 2 * batch_size\n",
        "        mask = torch.ones((N, N))\n",
        "        mask = mask.fill_diagonal_(0)\n",
        "        for i in range(batch_size):\n",
        "            mask[i, batch_size + i] = 0\n",
        "            mask[batch_size + i, i] = 0\n",
        "        mask = mask.bool()\n",
        "        return mask\n",
        "\n",
        "    def forward(self, z_i, z_j):\n",
        "        N = 2 * self.batch_size\n",
        "        z = torch.cat((z_i, z_j), dim=0)\n",
        "\n",
        "        sim = torch.matmul(z, z.T) / self.temperature\n",
        "        sim_i_j = torch.diag(sim, self.batch_size)\n",
        "        sim_j_i = torch.diag(sim, -self.batch_size)\n",
        "\n",
        "        positive_samples = torch.cat((sim_i_j, sim_j_i), dim=0).reshape(N, 1)\n",
        "        negative_samples = sim[self.mask].reshape(N, -1)\n",
        "\n",
        "        labels = torch.zeros(N).to(positive_samples.device).long()\n",
        "        logits = torch.cat((positive_samples, negative_samples), dim=1)\n",
        "        loss = self.criterion(logits, labels)\n",
        "        loss /= N\n",
        "\n",
        "        return loss\n",
        "\n",
        "\n",
        "class ClusterLoss(nn.Module):\n",
        "    def __init__(self, class_num, temperature, device):\n",
        "        super(ClusterLoss, self).__init__()\n",
        "        self.class_num = class_num\n",
        "        self.temperature = temperature\n",
        "        self.device = device\n",
        "\n",
        "        self.mask = self.mask_correlated_clusters(class_num)\n",
        "        self.criterion = nn.CrossEntropyLoss(reduction=\"sum\")\n",
        "        self.similarity_f = nn.CosineSimilarity(dim=2)\n",
        "\n",
        "    def mask_correlated_clusters(self, class_num):\n",
        "        N = 2 * class_num\n",
        "        mask = torch.ones((N, N))\n",
        "        mask = mask.fill_diagonal_(0)\n",
        "        for i in range(class_num):\n",
        "            mask[i, class_num + i] = 0\n",
        "            mask[class_num + i, i] = 0\n",
        "        mask = mask.bool()\n",
        "        return mask\n",
        "\n",
        "    def forward(self, c_i, c_j):\n",
        "        p_i = c_i.sum(0).view(-1)\n",
        "        p_i /= p_i.sum()\n",
        "        ne_i = math.log(p_i.size(0)) + (p_i * torch.log(p_i)).sum()\n",
        "        p_j = c_j.sum(0).view(-1)\n",
        "        p_j /= p_j.sum()\n",
        "        ne_j = math.log(p_j.size(0)) + (p_j * torch.log(p_j)).sum()\n",
        "        ne_loss = ne_i + ne_j\n",
        "\n",
        "        c_i = c_i.t()\n",
        "        c_j = c_j.t()\n",
        "        N = 2 * self.class_num\n",
        "        c = torch.cat((c_i, c_j), dim=0)\n",
        "\n",
        "        sim = self.similarity_f(c.unsqueeze(1), c.unsqueeze(0)) / self.temperature\n",
        "        sim_i_j = torch.diag(sim, self.class_num)\n",
        "        sim_j_i = torch.diag(sim, -self.class_num)\n",
        "\n",
        "        positive_clusters = torch.cat((sim_i_j, sim_j_i), dim=0).reshape(N, 1)\n",
        "        negative_clusters = sim[self.mask].reshape(N, -1)\n",
        "\n",
        "        labels = torch.zeros(N).to(positive_clusters.device).long()\n",
        "        logits = torch.cat((positive_clusters, negative_clusters), dim=1)\n",
        "        loss = self.criterion(logits, labels)\n",
        "        loss /= N\n",
        "\n",
        "        return loss + ne_loss\n"
      ],
      "metadata": {
        "id": "4l8dqmgwQeul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main implementation of proposed model"
      ],
      "metadata": {
        "id": "QzFtXsn-tnCo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Network(nn.Module):\n",
        "    def __init__(self, resnet, feature_dim, class_num):\n",
        "        super(Network, self).__init__()\n",
        "        self.resnet = resnet\n",
        "        self.feature_dim = feature_dim\n",
        "        self.cluster_num = class_num\n",
        "        self.instance_projector = nn.Sequential(\n",
        "            nn.Linear(self.resnet.rep_dim, self.resnet.rep_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(self.resnet.rep_dim, self.feature_dim),\n",
        "        )\n",
        "        self.cluster_projector = nn.Sequential(\n",
        "            nn.Linear(self.resnet.rep_dim, self.resnet.rep_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(self.resnet.rep_dim, self.cluster_num),\n",
        "            nn.Softmax(dim=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x_i, x_j):\n",
        "        h_i = self.resnet(x_i)\n",
        "        h_j = self.resnet(x_j)\n",
        "\n",
        "        z_i = normalize(self.instance_projector(h_i), dim=1)\n",
        "        z_j = normalize(self.instance_projector(h_j), dim=1)\n",
        "\n",
        "        c_i = self.cluster_projector(h_i)\n",
        "        c_j = self.cluster_projector(h_j)\n",
        "\n",
        "        return z_i, z_j, c_i, c_j\n",
        "\n",
        "    def forward_cluster(self, x):\n",
        "        h = self.resnet(x)\n",
        "        c = self.cluster_projector(h)\n",
        "        c = torch.argmax(c, dim=1)\n",
        "        return c\n"
      ],
      "metadata": {
        "id": "gteGi38jQnzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Resnet34 implementation which is used as backbone for fair comparison in the original paper"
      ],
      "metadata": {
        "id": "inAlm1oWuJ4a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, num_classes=1000, zero_init_residual=False,\n",
        "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n",
        "                 norm_layer=None):\n",
        "        super(ResNet, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        self._norm_layer = norm_layer\n",
        "\n",
        "        self.inplanes = 64\n",
        "        self.dilation = 1\n",
        "        if replace_stride_with_dilation is None:\n",
        "            replace_stride_with_dilation = [False, False, False]\n",
        "        if len(replace_stride_with_dilation) != 3:\n",
        "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
        "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
        "        self.groups = groups\n",
        "        self.base_width = width_per_group\n",
        "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "        self.bn1 = norm_layer(self.inplanes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[0])\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[1])\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[2])\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.rep_dim = 512 * block.expansion\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "        # Zero-initialize the last BN in each residual branch,\n",
        "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
        "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
        "        if zero_init_residual:\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, Bottleneck):\n",
        "                    nn.init.constant_(m.bn3.weight, 0)\n",
        "                elif isinstance(m, BasicBlock):\n",
        "                    nn.init.constant_(m.bn2.weight, 0)\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
        "        norm_layer = self._norm_layer\n",
        "        downsample = None\n",
        "        previous_dilation = self.dilation\n",
        "        if dilate:\n",
        "            self.dilation *= stride\n",
        "            stride = 1\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
        "                norm_layer(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
        "                            self.base_width, previous_dilation, norm_layer))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
        "                                base_width=self.base_width, dilation=self.dilation,\n",
        "                                norm_layer=norm_layer))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def _forward_impl(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self._forward_impl(x)\n",
        "\n",
        "\n",
        "def get_resnet(name):\n",
        "    resnet34 = ResNet(block=BasicBlock, layers=[3, 4, 6, 3])\n",
        "\n",
        "    resnets = {\n",
        "        \"ResNet34\": resnet34,\n",
        "    }\n",
        "    if name not in resnets.keys():\n",
        "        raise KeyError(f\"{name} is not a valid ResNet version\")\n",
        "    return resnets[name]\n"
      ],
      "metadata": {
        "id": "xBk74OrkQqEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transformation and Gaussian blur to blur the image"
      ],
      "metadata": {
        "id": "cvXU5O6Iujl9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GaussianBlur:\n",
        "    def __init__(self, kernel_size, min=0.1, max=2.0):\n",
        "        self.min = min\n",
        "        self.max = max\n",
        "        self.kernel_size = kernel_size\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        sample = np.array(sample)\n",
        "        prob = np.random.random_sample()\n",
        "        if prob < 0.5:\n",
        "            sigma = (self.max - self.min) * np.random.random_sample() + self.min\n",
        "            sample = cv2.GaussianBlur(sample, (self.kernel_size, self.kernel_size), sigma)\n",
        "        return sample\n",
        "\n",
        "\n",
        "class Transforms:\n",
        "    def __init__(self, size, s=1.0, mean=None, std=None, blur=False):\n",
        "        self.train_transform = [\n",
        "            torchvision.transforms.RandomResizedCrop(size=size),\n",
        "            torchvision.transforms.RandomHorizontalFlip(),\n",
        "            torchvision.transforms.RandomApply([torchvision.transforms.ColorJitter(0.8 * s, 0.8 * s, 0.8 * s, 0.2 * s)],\n",
        "                                               p=0.8),\n",
        "            torchvision.transforms.RandomGrayscale(p=0.2),\n",
        "        ]\n",
        "        if blur:\n",
        "            self.train_transform.append(GaussianBlur(kernel_size=23))\n",
        "        self.train_transform.append(torchvision.transforms.ToTensor())\n",
        "        self.test_transform = [\n",
        "            torchvision.transforms.Resize(size=(size, size)),\n",
        "            torchvision.transforms.ToTensor(),\n",
        "        ]\n",
        "        if mean and std:\n",
        "            self.train_transform.append(torchvision.transforms.Normalize(mean=mean, std=std))\n",
        "            self.test_transform.append(torchvision.transforms.Normalize(mean=mean, std=std))\n",
        "        self.train_transform = torchvision.transforms.Compose(self.train_transform)\n",
        "        self.test_transform = torchvision.transforms.Compose(self.test_transform)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        return self.train_transform(x), self.train_transform(x)\n"
      ],
      "metadata": {
        "id": "ZmxRUYzgQr9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "b6gMpdu8vA48"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyQ6Z9H-KIj5",
        "outputId": "46676d4c-dc23-40d6-94c1-ef4e92343e34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step [0/11]\t loss_instance: 5.514197826385498\t loss_cluster: 2.430302143096924\n",
            "Epoch [1/100]\t Loss: 7.759407303550026\n",
            "Step [0/11]\t loss_instance: 5.319942474365234\t loss_cluster: 2.212207317352295\n",
            "Epoch [2/100]\t Loss: 7.422675826332786\n",
            "Step [0/11]\t loss_instance: 5.437200546264648\t loss_cluster: 2.193316698074341\n",
            "Epoch [3/100]\t Loss: 7.415146784348921\n",
            "Step [0/11]\t loss_instance: 5.304917812347412\t loss_cluster: 2.117854595184326\n",
            "Epoch [4/100]\t Loss: 7.354842402718284\n",
            "Step [0/11]\t loss_instance: 5.138856887817383\t loss_cluster: 2.0897817611694336\n",
            "Epoch [5/100]\t Loss: 7.32236723466353\n",
            "Step [0/11]\t loss_instance: 5.172810077667236\t loss_cluster: 2.0502753257751465\n",
            "Epoch [6/100]\t Loss: 7.2449844967235215\n",
            "Step [0/11]\t loss_instance: 5.174536228179932\t loss_cluster: 2.110349655151367\n",
            "Epoch [7/100]\t Loss: 7.236055504192006\n",
            "Step [0/11]\t loss_instance: 5.122867584228516\t loss_cluster: 2.0262434482574463\n",
            "Epoch [8/100]\t Loss: 7.198570511557839\n",
            "Step [0/11]\t loss_instance: 5.174371242523193\t loss_cluster: 2.0349831581115723\n",
            "Epoch [9/100]\t Loss: 7.203426447781649\n",
            "Step [0/11]\t loss_instance: 5.338264465332031\t loss_cluster: 2.088634490966797\n",
            "Epoch [10/100]\t Loss: 7.190165172923695\n",
            "Step [0/11]\t loss_instance: 5.0690999031066895\t loss_cluster: 2.0250329971313477\n",
            "Epoch [11/100]\t Loss: 7.0661114345897325\n",
            "Step [0/11]\t loss_instance: 4.970341205596924\t loss_cluster: 2.0128681659698486\n",
            "Epoch [12/100]\t Loss: 7.037284981120717\n",
            "Step [0/11]\t loss_instance: 5.18629264831543\t loss_cluster: 2.074190616607666\n",
            "Epoch [13/100]\t Loss: 7.083739714189009\n",
            "Step [0/11]\t loss_instance: 4.943725109100342\t loss_cluster: 1.9718199968338013\n",
            "Epoch [14/100]\t Loss: 7.059634468772194\n",
            "Step [0/11]\t loss_instance: 5.112572193145752\t loss_cluster: 1.9932942390441895\n",
            "Epoch [15/100]\t Loss: 7.082454204559326\n",
            "Step [0/11]\t loss_instance: 5.0499725341796875\t loss_cluster: 1.99026358127594\n",
            "Epoch [16/100]\t Loss: 7.106431484222412\n",
            "Step [0/11]\t loss_instance: 5.083281993865967\t loss_cluster: 2.0372705459594727\n",
            "Epoch [17/100]\t Loss: 6.95008542320945\n",
            "Step [0/11]\t loss_instance: 4.816098213195801\t loss_cluster: 1.957042932510376\n",
            "Epoch [18/100]\t Loss: 6.904165874827992\n",
            "Step [0/11]\t loss_instance: 5.012552738189697\t loss_cluster: 1.9936307668685913\n",
            "Epoch [19/100]\t Loss: 6.912086573514071\n",
            "Step [0/11]\t loss_instance: 4.951078414916992\t loss_cluster: 2.003970146179199\n",
            "Epoch [20/100]\t Loss: 6.95641565322876\n",
            "Step [0/11]\t loss_instance: 4.923035144805908\t loss_cluster: 1.9436718225479126\n",
            "Epoch [21/100]\t Loss: 6.920820279554888\n",
            "Step [0/11]\t loss_instance: 4.872371196746826\t loss_cluster: 2.0367064476013184\n",
            "Epoch [22/100]\t Loss: 6.8961874788457695\n",
            "Step [0/11]\t loss_instance: 4.792534828186035\t loss_cluster: 1.9551141262054443\n",
            "Epoch [23/100]\t Loss: 6.737721183083274\n",
            "Step [0/11]\t loss_instance: 5.006869792938232\t loss_cluster: 1.9863353967666626\n",
            "Epoch [24/100]\t Loss: 6.853353240273216\n",
            "Step [0/11]\t loss_instance: 4.872657775878906\t loss_cluster: 1.966484546661377\n",
            "Epoch [25/100]\t Loss: 6.763490156693892\n",
            "Step [0/11]\t loss_instance: 4.823023796081543\t loss_cluster: 1.9362667798995972\n",
            "Epoch [26/100]\t Loss: 6.7017694820057265\n",
            "Step [0/11]\t loss_instance: 4.753371238708496\t loss_cluster: 1.9180551767349243\n",
            "Epoch [27/100]\t Loss: 6.672303850000555\n",
            "Step [0/11]\t loss_instance: 4.745604991912842\t loss_cluster: 1.9470072984695435\n",
            "Epoch [28/100]\t Loss: 6.678971940820867\n",
            "Step [0/11]\t loss_instance: 4.640534400939941\t loss_cluster: 1.892725944519043\n",
            "Epoch [29/100]\t Loss: 6.639389384876598\n",
            "Step [0/11]\t loss_instance: 4.779117584228516\t loss_cluster: 1.9044798612594604\n",
            "Epoch [30/100]\t Loss: 6.64672699841586\n",
            "Step [0/11]\t loss_instance: 4.657888412475586\t loss_cluster: 1.8628638982772827\n",
            "Epoch [31/100]\t Loss: 6.689728260040283\n",
            "Step [0/11]\t loss_instance: 4.7646803855896\t loss_cluster: 1.9484071731567383\n",
            "Epoch [32/100]\t Loss: 6.675681721080434\n",
            "Step [0/11]\t loss_instance: 4.71281623840332\t loss_cluster: 1.9139792919158936\n",
            "Epoch [33/100]\t Loss: 6.608415040102872\n",
            "Step [0/11]\t loss_instance: 4.707963943481445\t loss_cluster: 1.902076244354248\n",
            "Epoch [34/100]\t Loss: 6.6159374930641865\n",
            "Step [0/11]\t loss_instance: 4.609953880310059\t loss_cluster: 1.8674322366714478\n",
            "Epoch [35/100]\t Loss: 6.600526679645885\n",
            "Step [0/11]\t loss_instance: 4.7132368087768555\t loss_cluster: 1.9291638135910034\n",
            "Epoch [36/100]\t Loss: 6.530722791498357\n",
            "Step [0/11]\t loss_instance: 4.577236175537109\t loss_cluster: 1.8308357000350952\n",
            "Epoch [37/100]\t Loss: 6.544580806385387\n",
            "Step [0/11]\t loss_instance: 4.623055934906006\t loss_cluster: 1.8576381206512451\n",
            "Epoch [38/100]\t Loss: 6.509002642198042\n",
            "Step [0/11]\t loss_instance: 4.613970756530762\t loss_cluster: 1.9135078191757202\n",
            "Epoch [39/100]\t Loss: 6.482016346671364\n",
            "Step [0/11]\t loss_instance: 4.672966957092285\t loss_cluster: 1.874651551246643\n",
            "Epoch [40/100]\t Loss: 6.541102669455788\n",
            "Step [0/11]\t loss_instance: 4.677102565765381\t loss_cluster: 1.8876522779464722\n",
            "Epoch [41/100]\t Loss: 6.512538519772616\n",
            "Step [0/11]\t loss_instance: 4.615261077880859\t loss_cluster: 1.8645013570785522\n",
            "Epoch [42/100]\t Loss: 6.456920320337469\n",
            "Step [0/11]\t loss_instance: 4.621411323547363\t loss_cluster: 1.897141933441162\n",
            "Epoch [43/100]\t Loss: 6.419492634859952\n",
            "Step [0/11]\t loss_instance: 4.568960666656494\t loss_cluster: 1.855242133140564\n",
            "Epoch [44/100]\t Loss: 6.473397558385676\n",
            "Step [0/11]\t loss_instance: 4.51846170425415\t loss_cluster: 1.804875373840332\n",
            "Epoch [45/100]\t Loss: 6.451610435139049\n",
            "Step [0/11]\t loss_instance: 4.584288597106934\t loss_cluster: 1.8634930849075317\n",
            "Epoch [46/100]\t Loss: 6.406606630845503\n",
            "Step [0/11]\t loss_instance: 4.565415382385254\t loss_cluster: 1.8819704055786133\n",
            "Epoch [47/100]\t Loss: 6.404077009721235\n",
            "Step [0/11]\t loss_instance: 4.511281967163086\t loss_cluster: 1.8389487266540527\n",
            "Epoch [48/100]\t Loss: 6.3971030061895195\n",
            "Step [0/11]\t loss_instance: 4.456022262573242\t loss_cluster: 1.8296672105789185\n",
            "Epoch [49/100]\t Loss: 6.3695266463539815\n",
            "Step [0/11]\t loss_instance: 4.471449851989746\t loss_cluster: 1.7920180559158325\n",
            "Epoch [50/100]\t Loss: 6.362115036357533\n",
            "Step [0/11]\t loss_instance: 4.4480366706848145\t loss_cluster: 1.7905725240707397\n",
            "Epoch [51/100]\t Loss: 6.328760103745894\n",
            "Step [0/11]\t loss_instance: 4.520670413970947\t loss_cluster: 1.8513131141662598\n",
            "Epoch [52/100]\t Loss: 6.333911072124135\n",
            "Step [0/11]\t loss_instance: 4.603182792663574\t loss_cluster: 1.8921401500701904\n",
            "Epoch [53/100]\t Loss: 6.375870834697377\n",
            "Step [0/11]\t loss_instance: 4.593297004699707\t loss_cluster: 1.8320711851119995\n",
            "Epoch [54/100]\t Loss: 6.336547201330012\n",
            "Step [0/11]\t loss_instance: 4.593893051147461\t loss_cluster: 1.8768069744110107\n",
            "Epoch [55/100]\t Loss: 6.305530721491033\n",
            "Step [0/11]\t loss_instance: 4.5003838539123535\t loss_cluster: 1.8308219909667969\n",
            "Epoch [56/100]\t Loss: 6.316551078449596\n",
            "Step [0/11]\t loss_instance: 4.413886070251465\t loss_cluster: 1.7668734788894653\n",
            "Epoch [57/100]\t Loss: 6.238665840842507\n",
            "Step [0/11]\t loss_instance: 4.518871307373047\t loss_cluster: 1.856755018234253\n",
            "Epoch [58/100]\t Loss: 6.3145503564314405\n",
            "Step [0/11]\t loss_instance: 4.516334533691406\t loss_cluster: 1.8042911291122437\n",
            "Epoch [59/100]\t Loss: 6.283996105194092\n",
            "Step [0/11]\t loss_instance: 4.458435535430908\t loss_cluster: 1.8327175378799438\n",
            "Epoch [60/100]\t Loss: 6.311484510248357\n",
            "Step [0/11]\t loss_instance: 4.525564193725586\t loss_cluster: 1.8216488361358643\n",
            "Epoch [61/100]\t Loss: 6.313279412009499\n",
            "Step [0/11]\t loss_instance: 4.497480869293213\t loss_cluster: 1.8573498725891113\n",
            "Epoch [62/100]\t Loss: 6.275948351079768\n",
            "Step [0/11]\t loss_instance: 4.4681715965271\t loss_cluster: 1.8137741088867188\n",
            "Epoch [63/100]\t Loss: 6.258688623254949\n",
            "Step [0/11]\t loss_instance: 4.44176721572876\t loss_cluster: 1.774931788444519\n",
            "Epoch [64/100]\t Loss: 6.237251064994118\n",
            "Step [0/11]\t loss_instance: 4.505112648010254\t loss_cluster: 1.7996997833251953\n",
            "Epoch [65/100]\t Loss: 6.24443344636397\n",
            "Step [0/11]\t loss_instance: 4.4125165939331055\t loss_cluster: 1.8193055391311646\n",
            "Epoch [66/100]\t Loss: 6.215225479819558\n",
            "Step [0/11]\t loss_instance: 4.443858623504639\t loss_cluster: 1.832590103149414\n",
            "Epoch [67/100]\t Loss: 6.238857052542946\n",
            "Step [0/11]\t loss_instance: 4.37816858291626\t loss_cluster: 1.8173704147338867\n",
            "Epoch [68/100]\t Loss: 6.215227950703014\n",
            "Step [0/11]\t loss_instance: 4.489798545837402\t loss_cluster: 1.8167201280593872\n",
            "Epoch [69/100]\t Loss: 6.218611413782293\n",
            "Step [0/11]\t loss_instance: 4.4463982582092285\t loss_cluster: 1.8042207956314087\n",
            "Epoch [70/100]\t Loss: 6.204096707430753\n",
            "Step [0/11]\t loss_instance: 4.342970848083496\t loss_cluster: 1.751722812652588\n",
            "Epoch [71/100]\t Loss: 6.168014873157848\n",
            "Step [0/11]\t loss_instance: 4.4009175300598145\t loss_cluster: 1.7519714832305908\n",
            "Epoch [72/100]\t Loss: 6.205529342998158\n",
            "Step [0/11]\t loss_instance: 4.394484519958496\t loss_cluster: 1.8018091917037964\n",
            "Epoch [73/100]\t Loss: 6.213356061415239\n",
            "Step [0/11]\t loss_instance: 4.39354944229126\t loss_cluster: 1.7597858905792236\n",
            "Epoch [74/100]\t Loss: 6.155421690507368\n",
            "Step [0/11]\t loss_instance: 4.326480388641357\t loss_cluster: 1.756944179534912\n",
            "Epoch [75/100]\t Loss: 6.217423525723544\n",
            "Step [0/11]\t loss_instance: 4.396361827850342\t loss_cluster: 1.811577320098877\n",
            "Epoch [76/100]\t Loss: 6.130482760342685\n",
            "Step [0/11]\t loss_instance: 4.366214275360107\t loss_cluster: 1.8030847311019897\n",
            "Epoch [77/100]\t Loss: 6.18322719227184\n",
            "Step [0/11]\t loss_instance: 4.359513759613037\t loss_cluster: 1.75832998752594\n",
            "Epoch [78/100]\t Loss: 6.201813611117276\n",
            "Step [0/11]\t loss_instance: 4.4139604568481445\t loss_cluster: 1.7812798023223877\n",
            "Epoch [79/100]\t Loss: 6.199329679662531\n",
            "Step [0/11]\t loss_instance: 4.3670549392700195\t loss_cluster: 1.8220834732055664\n",
            "Epoch [80/100]\t Loss: 6.158344528891823\n",
            "Step [0/11]\t loss_instance: 4.405113220214844\t loss_cluster: 1.8063185214996338\n",
            "Epoch [81/100]\t Loss: 6.177815784107555\n",
            "Step [0/11]\t loss_instance: 4.355231761932373\t loss_cluster: 1.7470797300338745\n",
            "Epoch [82/100]\t Loss: 6.172526142813942\n",
            "Step [0/11]\t loss_instance: 4.329758644104004\t loss_cluster: 1.777807354927063\n",
            "Epoch [83/100]\t Loss: 6.153429941697554\n",
            "Step [0/11]\t loss_instance: 4.34476900100708\t loss_cluster: 1.7757192850112915\n",
            "Epoch [84/100]\t Loss: 6.1335697607560595\n",
            "Step [0/11]\t loss_instance: 4.398448467254639\t loss_cluster: 1.8076263666152954\n",
            "Epoch [85/100]\t Loss: 6.113823153755882\n",
            "Step [0/11]\t loss_instance: 4.3509955406188965\t loss_cluster: 1.7811505794525146\n",
            "Epoch [86/100]\t Loss: 6.098804907365278\n",
            "Step [0/11]\t loss_instance: 4.3083295822143555\t loss_cluster: 1.776778221130371\n",
            "Epoch [87/100]\t Loss: 6.115248680114746\n",
            "Step [0/11]\t loss_instance: 4.314173698425293\t loss_cluster: 1.727126121520996\n",
            "Epoch [88/100]\t Loss: 6.14296158877286\n",
            "Step [0/11]\t loss_instance: 4.330322742462158\t loss_cluster: 1.7459343671798706\n",
            "Epoch [89/100]\t Loss: 6.102783246473833\n",
            "Step [0/11]\t loss_instance: 4.327871322631836\t loss_cluster: 1.8176802396774292\n",
            "Epoch [90/100]\t Loss: 6.100351550362327\n",
            "Step [0/11]\t loss_instance: 4.314824104309082\t loss_cluster: 1.7579474449157715\n",
            "Epoch [91/100]\t Loss: 6.052473111586138\n",
            "Step [0/11]\t loss_instance: 4.3178510665893555\t loss_cluster: 1.7662670612335205\n",
            "Epoch [92/100]\t Loss: 6.135198029604825\n",
            "Step [0/11]\t loss_instance: 4.292356967926025\t loss_cluster: 1.7703548669815063\n",
            "Epoch [93/100]\t Loss: 6.079312931407582\n",
            "Step [0/11]\t loss_instance: 4.325747966766357\t loss_cluster: 1.7554759979248047\n",
            "Epoch [94/100]\t Loss: 6.062461029399525\n",
            "Step [0/11]\t loss_instance: 4.333709239959717\t loss_cluster: 1.7453581094741821\n",
            "Epoch [95/100]\t Loss: 6.084703185341575\n",
            "Step [0/11]\t loss_instance: 4.306917190551758\t loss_cluster: 1.734506607055664\n",
            "Epoch [96/100]\t Loss: 6.094139619307085\n",
            "Step [0/11]\t loss_instance: 4.382823467254639\t loss_cluster: 1.7579808235168457\n",
            "Epoch [97/100]\t Loss: 6.080867377194491\n",
            "Step [0/11]\t loss_instance: 4.319492340087891\t loss_cluster: 1.8021613359451294\n",
            "Epoch [98/100]\t Loss: 6.108041156422008\n",
            "Step [0/11]\t loss_instance: 4.279533863067627\t loss_cluster: 1.7388824224472046\n",
            "Epoch [99/100]\t Loss: 6.070886785333807\n"
          ]
        }
      ],
      "source": [
        "def train():\n",
        "    loss_epoch = 0\n",
        "    for step, ((x_i, x_j), _) in enumerate(data_loader):\n",
        "        optimizer.zero_grad()\n",
        "        x_i = x_i.to('cuda')\n",
        "        x_j = x_j.to('cuda')\n",
        "        z_i, z_j, c_i, c_j = model(x_i, x_j)\n",
        "        loss_instance = criterion_instance(z_i, z_j)\n",
        "        loss_cluster = criterion_cluster(c_i, c_j)\n",
        "        loss = loss_instance + loss_cluster\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if step % 50 == 0:\n",
        "            print(\n",
        "                f\"Step [{step}/{len(data_loader)}]\\t loss_instance: {loss_instance.item()}\\t loss_cluster: {loss_cluster.item()}\")\n",
        "        loss_epoch += loss.item()\n",
        "    return loss_epoch\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    torch.manual_seed(42)\n",
        "    torch.cuda.manual_seed_all(42)\n",
        "    torch.cuda.manual_seed(42)\n",
        "    np.random.seed(42)\n",
        "\n",
        "    # prepare data\n",
        "    dataset = torchvision.datasets.ImageFolder(\n",
        "            root='/content/dataset',\n",
        "            transform=Transforms(size=224, blur=True),\n",
        "        )\n",
        "    class_num = 6\n",
        "    data_loader = torch.utils.data.DataLoader(\n",
        "        dataset,\n",
        "        batch_size=128,\n",
        "        shuffle=True,\n",
        "        drop_last=True,\n",
        "        num_workers=4,\n",
        "    )\n",
        "    # initialize model\n",
        "    res = get_resnet(\"ResNet34\")\n",
        "    model = Network(res, 128, class_num)\n",
        "    model = model.to('cuda')\n",
        "    # optimizer / loss\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0003, weight_decay=0.)\n",
        "    loss_device = torch.device(\"cuda\")\n",
        "    criterion_instance = InstanceLoss(128, 0.5, loss_device).to(loss_device)\n",
        "    criterion_cluster = ClusterLoss(class_num, 1.0, loss_device).to(loss_device)\n",
        "    # train\n",
        "    for epoch in range(1, 100):\n",
        "        lr = optimizer.param_groups[0][\"lr\"]\n",
        "        loss_epoch = train()\n",
        "        if epoch==0:\n",
        "            save_model('/content/Model', model, optimizer, epoch)\n",
        "        if epoch==20:\n",
        "            save_model('/content/Model', model, optimizer, epoch)\n",
        "        if epoch==50:\n",
        "            save_model('/content/Model', model, optimizer, epoch)\n",
        "        print(f\"Epoch [{epoch}/{100}]\\t Loss: {loss_epoch / len(data_loader)}\")\n",
        "    save_model('/content/Model', model, optimizer, 100)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install munkres"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqPPVC-rSHjb",
        "outputId": "1034e0fa-1cdb-46e5-93df-ead681362f45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting munkres\n",
            "  Downloading munkres-1.1.4-py2.py3-none-any.whl (7.0 kB)\n",
            "Installing collected packages: munkres\n",
            "Successfully installed munkres-1.1.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing phase"
      ],
      "metadata": {
        "id": "WvWW968KvLma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from munkres import Munkres\n",
        "\n",
        "def evaluate(label, pred):\n",
        "    nmi = metrics.normalized_mutual_info_score(label, pred)\n",
        "    ari = metrics.adjusted_rand_score(label, pred)\n",
        "    f = metrics.fowlkes_mallows_score(label, pred)\n",
        "    pred_adjusted = get_y_preds(label, pred, len(set(label)))\n",
        "    acc = metrics.accuracy_score(pred_adjusted, label)\n",
        "    return nmi, ari, f, acc\n",
        "\n",
        "\n",
        "def calculate_cost_matrix(C, n_clusters):\n",
        "    cost_matrix = np.zeros((n_clusters, n_clusters))\n",
        "    for j in range(n_clusters):\n",
        "        s = np.sum(C[:, j])\n",
        "        for i in range(n_clusters):\n",
        "            t = C[i, j]\n",
        "            cost_matrix[j, i] = s - t\n",
        "    return cost_matrix\n",
        "\n",
        "\n",
        "def get_cluster_labels_from_indices(indices):\n",
        "    n_clusters = len(indices)\n",
        "    cluster_labels = np.zeros(n_clusters)\n",
        "    for i in range(n_clusters):\n",
        "        cluster_labels[i] = indices[i][1]\n",
        "    return cluster_labels\n",
        "\n",
        "def get_y_preds(y_true, cluster_assignments, n_clusters):\n",
        "    confusion_matrix = metrics.confusion_matrix(y_true, cluster_assignments, labels=None)\n",
        "    cost_matrix = calculate_cost_matrix(confusion_matrix, n_clusters)\n",
        "    indices = Munkres().compute(cost_matrix)\n",
        "    kmeans_to_true_cluster_labels = get_cluster_labels_from_indices(indices)\n",
        "    if np.min(cluster_assignments) != 0:\n",
        "        cluster_assignments = cluster_assignments - np.min(cluster_assignments)\n",
        "    y_pred = kmeans_to_true_cluster_labels[cluster_assignments]\n",
        "    return y_pred"
      ],
      "metadata": {
        "id": "-BcHVLVUR9KF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Result after 20 epochs"
      ],
      "metadata": {
        "id": "epBYv4YPvV7a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "def inference(loader, model, device):\n",
        "    model.eval()\n",
        "    feature_vector = []\n",
        "    labels_vector = []\n",
        "    for step, (x, y) in enumerate(loader):\n",
        "        x = x.to(device)\n",
        "        with torch.no_grad():\n",
        "            c = model.forward_cluster(x)\n",
        "        c = c.detach()\n",
        "        feature_vector.extend(c.cpu().detach().numpy())\n",
        "        labels_vector.extend(y.numpy())\n",
        "        if step % 20 == 0:\n",
        "            print(f\"Step [{step}/{len(loader)}]\\t Computing features...\")\n",
        "    feature_vector = np.array(feature_vector)\n",
        "    labels_vector = np.array(labels_vector)\n",
        "    print(\"Features shape {}\".format(feature_vector.shape))\n",
        "    return feature_vector, labels_vector\n",
        "\n",
        "dataset = torchvision.datasets.ImageFolder(\n",
        "        root='/content/dataset',\n",
        "        transform=Transforms(size=224).test_transform,\n",
        "    )\n",
        "class_num = 6\n",
        "data_loader = torch.utils.data.DataLoader(\n",
        "    dataset,\n",
        "    batch_size=500,\n",
        "    shuffle=False,\n",
        "    drop_last=False,\n",
        "    num_workers=4,\n",
        ")\n",
        "\n",
        "res = get_resnet('ResNet34')\n",
        "model = Network(res, 128, class_num)\n",
        "model_fp = os.path.join('/content/Model', \"checkpoint_{}.tar\".format('20'))\n",
        "model.load_state_dict(torch.load(model_fp, map_location=device.type)['net'])\n",
        "model.to(device)\n",
        "\n",
        "print(\"### Creating features from model ###\")\n",
        "X, Y = inference(data_loader, model, device)\n",
        "nmi, ari, f, acc = evaluate(Y, X)\n",
        "print(\"NMI, ARI, F, ACC at 20 epoch\")\n",
        "print('NMI = {:.4f} ARI = {:.4f} F = {:.4f} ACC = {:.4f}'.format(nmi, ari, f, acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8OgQlrXxYI2",
        "outputId": "be22af73-b167-4be2-fb71-3c3b6ef5a080"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Creating features from model ###\n",
            "Step [0/4]\t Computing features...\n",
            "Features shape (1530,)\n",
            "6 1530\n",
            "NMI, ARI, F, ACC at 20 epoch\n",
            "NMI = 0.3404 ARI = 0.2909 F = 0.4276 ACC = 0.5667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Result after 50 epochs"
      ],
      "metadata": {
        "id": "lDOUxOwQvdsN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "def inference(loader, model, device):\n",
        "    model.eval()\n",
        "    feature_vector = []\n",
        "    labels_vector = []\n",
        "    for step, (x, y) in enumerate(loader):\n",
        "        x = x.to(device)\n",
        "        with torch.no_grad():\n",
        "            c = model.forward_cluster(x)\n",
        "        c = c.detach()\n",
        "        feature_vector.extend(c.cpu().detach().numpy())\n",
        "        labels_vector.extend(y.numpy())\n",
        "        if step % 20 == 0:\n",
        "            print(f\"Step [{step}/{len(loader)}]\\t Computing features...\")\n",
        "    feature_vector = np.array(feature_vector)\n",
        "    labels_vector = np.array(labels_vector)\n",
        "    print(\"Features shape {}\".format(feature_vector.shape))\n",
        "    return feature_vector, labels_vector\n",
        "\n",
        "dataset = torchvision.datasets.ImageFolder(\n",
        "        root='/content/dataset',\n",
        "        transform=Transforms(size=224).test_transform,\n",
        "    )\n",
        "class_num = 6\n",
        "data_loader = torch.utils.data.DataLoader(\n",
        "    dataset,\n",
        "    batch_size=500,\n",
        "    shuffle=False,\n",
        "    drop_last=False,\n",
        "    num_workers=4,\n",
        ")\n",
        "\n",
        "res = get_resnet('ResNet34')\n",
        "model = Network(res, 128, class_num)\n",
        "model_fp = os.path.join('/content/Model', \"checkpoint_{}.tar\".format('50'))\n",
        "model.load_state_dict(torch.load(model_fp, map_location=device.type)['net'])\n",
        "model.to(device)\n",
        "\n",
        "print(\"### Creating features from model ###\")\n",
        "X, Y = inference(data_loader, model, device)\n",
        "nmi, ari, f, acc = evaluate(Y, X)\n",
        "print(\"NMI, ARI, F, ACC at 50 epoch\")\n",
        "print('NMI = {:.4f} ARI = {:.4f} F = {:.4f} ACC = {:.4f}'.format(nmi, ari, f, acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7cd1QaORe0m",
        "outputId": "b4e2ce3a-ffce-4285-de42-e9683683a696"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Creating features from model ###\n",
            "Step [0/4]\t Computing features...\n",
            "Features shape (1530,)\n",
            "6 1530\n",
            "NMI, ARI, F, ACC at 50 epoch\n",
            "NMI = 0.4812 ARI = 0.4644 F = 0.5627 ACC = 0.6719\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Result after 100 epochs"
      ],
      "metadata": {
        "id": "pHRXuD9bviXb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "def inference(loader, model, device):\n",
        "    model.eval()\n",
        "    feature_vector = []\n",
        "    labels_vector = []\n",
        "    for step, (x, y) in enumerate(loader):\n",
        "        x = x.to(device)\n",
        "        with torch.no_grad():\n",
        "            c = model.forward_cluster(x)\n",
        "        c = c.detach()\n",
        "        feature_vector.extend(c.cpu().detach().numpy())\n",
        "        labels_vector.extend(y.numpy())\n",
        "        if step % 20 == 0:\n",
        "            print(f\"Step [{step}/{len(loader)}]\\t Computing features...\")\n",
        "    feature_vector = np.array(feature_vector)\n",
        "    labels_vector = np.array(labels_vector)\n",
        "    print(\"Features shape {}\".format(feature_vector.shape))\n",
        "    return feature_vector, labels_vector\n",
        "\n",
        "dataset = torchvision.datasets.ImageFolder(\n",
        "        root='/content/dataset',\n",
        "        transform=Transforms(size=224).test_transform,\n",
        "    )\n",
        "class_num = 6\n",
        "data_loader = torch.utils.data.DataLoader(\n",
        "    dataset,\n",
        "    batch_size=500,\n",
        "    shuffle=False,\n",
        "    drop_last=False,\n",
        "    num_workers=4,\n",
        ")\n",
        "\n",
        "res = get_resnet('ResNet34')\n",
        "model = Network(res, 128, class_num)\n",
        "model_fp = os.path.join('/content/Model', \"checkpoint_{}.tar\".format('100'))\n",
        "model.load_state_dict(torch.load(model_fp, map_location=device.type)['net'])\n",
        "model.to(device)\n",
        "\n",
        "print(\"### Creating features from model ###\")\n",
        "X, Y = inference(data_loader, model, device)\n",
        "nmi, ari, f, acc = evaluate(Y, X)\n",
        "print(\"NMI, ARI, F, ACC at 100 epoch\")\n",
        "print('NMI = {:.4f} ARI = {:.4f} F = {:.4f} ACC = {:.4f}'.format(nmi, ari, f, acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CD_akJ70xUBW",
        "outputId": "4496ef7b-61a3-4260-c655-d97cf2deb6c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Creating features from model ###\n",
            "Step [0/4]\t Computing features...\n",
            "Features shape (1530,)\n",
            "6 1530\n",
            "NMI, ARI, F, ACC at 100 epoch\n",
            "NMI = 0.5169 ARI = 0.4550 F = 0.5551 ACC = 0.6458\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***As the size of dataset was very less as compared to the datasets used in the paper. The accuracy which we got after 20, 50 and 100 epochs is shown above. Hence part 3 also completed by implementing everything from scratch.***"
      ],
      "metadata": {
        "id": "xo04jKx2vofD"
      }
    }
  ]
}